# EDLM_Whisper_Boost
Выпускной проект курса "Эффективные модели глубокого обучения" по теме ускорения модели Whisper

## Профилировка и бейзлайн
Бейзлайн метрик модели Whisper Large:

| Device | WER   | CER   | Avg Time per Audio (s) |
|--------|-------|-------|------------------------|
| CPU    | 0.4403 | 0.1583 | 8.7137                 |
| GPU    | 0.4403 | 0.1583 | 0.8386                 |

Профилировка показывает следующее:
1. Подавляющее большинство операций на CPU и значимая часть на GPU - операции aten::addmm типа output = beta * input + alpha * (mat1 @ mat2), которые по сути являются умножениями матриц в линейном слое. В теории, прунинг должен уменьшать количество таких операций, а, значит и положительно влиять на скорость инференса.
2. Самые тяжелые операции на GPU aten::_efficient_attention_forward и fmha_cutlassF_f32_aligned_64x64_rf_sm80 - эффективное вычисление аттеншена и на них потенциально может помочь квантизация или mixed precision.

## Pruning
