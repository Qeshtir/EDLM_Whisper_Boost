{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b2f0b99c-4578-44b6-a456-61b7f912bf87",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "from torch.profiler import profile, record_function, ProfilerActivity\n",
    "import pandas as pd\n",
    "from datasets import load_dataset\n",
    "from transformers import WhisperProcessor, WhisperForConditionalGeneration\n",
    "import torch.quantization\n",
    "import torch.ao.quantization as tq\n",
    "import gc\n",
    "\n",
    "import jiwer\n",
    "from jiwer import (\n",
    "    Compose,\n",
    "    ToLowerCase,\n",
    "    RemoveMultipleSpaces,\n",
    "    Strip,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9652d098-c5a7-4e57-a3f4-bb0ec2ecc698",
   "metadata": {},
   "source": [
    "# Final experiment\n",
    "В этом ноутбуке проверяется гипотеза, что пропруненная ранее модель с базовой квантизацией и компиляцией даёт лучшие результаты. Прогон ноутбука произведён на тестовом сервере прунинга, поэтому результаты могут незначительно отличаться от метрик бэйзлайна.\n",
    "\n",
    "Все значения профилировщика были сняты в прогоне на чистовую вне изолированной среды, поэтому значения могут отличаться, но статистически сводятся к итоговым метрикам."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ae18e1e5-24fc-409b-babd-cef272baeae7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_size_of_model(model):\n",
    "    \"\"\" Prints the real size of the model \"\"\"\n",
    "    torch.save(model.state_dict(), \"temp.p\")\n",
    "    print('Size (MB):', os.path.getsize(\"temp.p\")/1e6)\n",
    "    os.remove('temp.p')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e58fb1fa-874c-410a-b47d-180b6115d512",
   "metadata": {},
   "outputs": [],
   "source": [
    "def asr_metrics(hypothesis: str, reference: str):\n",
    "    tr = Compose([ToLowerCase(), RemoveMultipleSpaces(), Strip()])\n",
    "\n",
    "    ref_tr = tr(reference)\n",
    "    hyp_tr = tr(hypothesis)\n",
    "\n",
    "    out = jiwer.process_words(ref_tr, hyp_tr)\n",
    "    wer = out.wer\n",
    "    # S, D, I = out.substitutions, out.deletions, out.insertions\n",
    "\n",
    "    cer = jiwer.cer(ref_tr, hyp_tr) # ?????\n",
    "\n",
    "    return {\n",
    "        \"wer\": wer,\n",
    "        \"cer\": cer,\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "059ea448-06fe-4a2b-bc43-1ced9c20b905",
   "metadata": {},
   "outputs": [],
   "source": [
    "def profile_sample(sample_idx=0, trace_path=\"whisper_perfetto_large-v3.json\", sort_by=\"cpu_time_total\", model=None):\n",
    "    example = dataset[sample_idx]\n",
    "    audio_array = example[\"audio\"][\"array\"]\n",
    "    sampling_rate = example[\"audio\"][\"sampling_rate\"]\n",
    "\n",
    "    inputs = processor(audio_array, sampling_rate=sampling_rate, return_tensors=\"pt\").input_features\n",
    "\n",
    "    with profile(\n",
    "        activities=[ProfilerActivity.CPU],\n",
    "        record_shapes=True,\n",
    "        profile_memory=True,\n",
    "        with_stack=False,\n",
    "    ) as prof:\n",
    "        with record_function(\"whisper.generate\"):\n",
    "            predicted_ids = model.generate(inputs, forced_decoder_ids=forced_decoder_ids)\n",
    "\n",
    "    prof.export_chrome_trace(trace_path)\n",
    "    print(f\"Perfetto trace saved to {trace_path}\")\n",
    "    print(prof.key_averages().table(\n",
    "        sort_by=sort_by,\n",
    "        row_limit=10\n",
    "    ))\n",
    "    return processor.decode(predicted_ids[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8ca2588d-c490-4ed8-a4d2-63cdccf5079e",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = load_dataset(\"bond005/sberdevices_golos_10h_crowd\", split=\"validation\") #, split=\"test\")\n",
    "# dataset = dataset.select(range(100))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9620f501-f726-4111-a66a-1f055a736ec5",
   "metadata": {},
   "source": [
    "# --TO_DO - загрузить базовую модель здесь"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "afaa4d97-cb9c-4238-bbde-f955c671a066",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size (MB): 6174.372281\n"
     ]
    }
   ],
   "source": [
    "processor = WhisperProcessor.from_pretrained(\"openai/whisper-large-v3\")\n",
    "model = WhisperForConditionalGeneration.from_pretrained(\"openai/whisper-large-v3\")\n",
    "forced_decoder_ids = processor.get_decoder_prompt_ids(language=\"russian\", task=\"transcribe\")\n",
    "print_size_of_model(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "af428acb-7dd7-4215-8591-156f44a1f954",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WhisperForConditionalGeneration(\n",
      "  (model): WhisperModel(\n",
      "    (encoder): WhisperEncoder(\n",
      "      (conv1): Conv1d(128, 1280, kernel_size=(3,), stride=(1,), padding=(1,))\n",
      "      (conv2): Conv1d(1280, 1280, kernel_size=(3,), stride=(2,), padding=(1,))\n",
      "      (embed_positions): Embedding(1500, 1280)\n",
      "      (layers): ModuleList(\n",
      "        (0-31): 32 x WhisperEncoderLayer(\n",
      "          (self_attn): WhisperAttention(\n",
      "            (k_proj): Linear(in_features=1280, out_features=1280, bias=False)\n",
      "            (v_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
      "            (q_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
      "            (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
      "          )\n",
      "          (self_attn_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
      "          (activation_fn): GELUActivation()\n",
      "          (fc1): Linear(in_features=1280, out_features=5120, bias=True)\n",
      "          (fc2): Linear(in_features=5120, out_features=1280, bias=True)\n",
      "          (final_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
      "        )\n",
      "      )\n",
      "      (layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
      "    )\n",
      "    (decoder): WhisperDecoder(\n",
      "      (embed_tokens): Embedding(51866, 1280, padding_idx=50256)\n",
      "      (embed_positions): WhisperPositionalEmbedding(448, 1280)\n",
      "      (layers): ModuleList(\n",
      "        (0-31): 32 x WhisperDecoderLayer(\n",
      "          (self_attn): WhisperAttention(\n",
      "            (k_proj): Linear(in_features=1280, out_features=1280, bias=False)\n",
      "            (v_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
      "            (q_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
      "            (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
      "          )\n",
      "          (activation_fn): GELUActivation()\n",
      "          (self_attn_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
      "          (encoder_attn): WhisperAttention(\n",
      "            (k_proj): Linear(in_features=1280, out_features=1280, bias=False)\n",
      "            (v_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
      "            (q_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
      "            (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
      "          )\n",
      "          (encoder_attn_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
      "          (fc1): Linear(in_features=1280, out_features=5120, bias=True)\n",
      "          (fc2): Linear(in_features=5120, out_features=1280, bias=True)\n",
      "          (final_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
      "        )\n",
      "      )\n",
      "      (layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
      "    )\n",
      "  )\n",
      "  (proj_out): Linear(in_features=1280, out_features=51866, bias=False)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# Посмотрим на архитектуру модели\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "9282cdb6-2d8f-41d7-8d7c-311729106c5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_model(verbose=False, model=None, dataset=None):\n",
    "    results = []\n",
    "    i = 0\n",
    "    for audio in tqdm(dataset):\n",
    "        audio_array = audio[\"audio\"][\"array\"]\n",
    "        sampling_rate = audio[\"audio\"][\"sampling_rate\"]\n",
    "        reference = audio[\"transcription\"]\n",
    "    \n",
    "        start_time = time.time()\n",
    "        input_features = processor(audio_array, sampling_rate=sampling_rate, return_tensors=\"pt\").input_features \n",
    "        predicted_ids = model.generate(input_features, forced_decoder_ids=forced_decoder_ids)[0] #Уточнить в зависимости от выбранной модели\n",
    "        hypothesis = processor.decode(predicted_ids)\n",
    "        run_time = time.time() - start_time\n",
    "        metrics = asr_metrics(hypothesis, reference)\n",
    "        metrics[\"run_time_sec\"] = run_time\n",
    "        if verbose:\n",
    "            if i % 50 == 0:\n",
    "                print(\"referenct:\")\n",
    "                print(reference)\n",
    "                print(\"hypothesis:\")\n",
    "                print(hypothesis)\n",
    "            i += 1\n",
    "        results.append(metrics)\n",
    "\n",
    "    df_results = pd.DataFrame(results)\n",
    "    \n",
    "    summary = {\n",
    "        \"total_samples\": len(df_results),\n",
    "        \"avg_wer\": df_results[\"wer\"].mean(),\n",
    "        \"avg_cer\": df_results[\"cer\"].mean(),\n",
    "        \"avg_time_per_audio\": df_results[\"run_time_sec\"].mean(),\n",
    "        \"total_time\": df_results[\"run_time_sec\"].sum(),\n",
    "    }\n",
    "    \n",
    "    print(\"large-v3\")\n",
    "    print(json.dumps(summary, ensure_ascii=True, indent=2))\n",
    "    return summary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ea957dd-af6f-41e5-a42b-01a8f9634045",
   "metadata": {},
   "source": [
    "# CPU\n",
    "Профилировка базовой модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46cab216-b2b7-47ff-9349-a51e4218f2e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = profile_sample(116, trace_path=\"whisper_perfetto_large-v3_base.json\", model=model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ed15432-37b1-4633-a054-ddb4452f4871",
   "metadata": {},
   "outputs": [],
   "source": [
    "del model, _\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58326415-11ca-4f52-b6f5-26fdabe54e94",
   "metadata": {},
   "source": [
    "# -- TO_DO Грузим запруненную модель"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "196f4e55-9289-44e5-a09b-29d1e76b3e5d",
   "metadata": {},
   "source": [
    "Профилировка запруненной модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2421e128-1a38-433c-b43a-d9495bb8f96f",
   "metadata": {},
   "outputs": [],
   "source": [
    "pruned_model = WhisperForConditionalGeneration.from_pretrained(\"pruned_081\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a798884-aa11-4fa5-a1bd-2f3d6a13ef3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = profile_sample(116, trace_path=\"whisper_perfetto_large-v3_pruned_base.json\", model=pruned_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "58cf44a1-10a3-4af3-933e-cebf88d068b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 50/50 [06:50<00:00,  8.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "large-v3\n",
      "{\n",
      "  \"total_samples\": 50,\n",
      "  \"avg_wer\": 0.3984776334776335,\n",
      "  \"avg_cer\": 0.14465731826243972,\n",
      "  \"avg_time_per_audio\": 8.201239647865295,\n",
      "  \"total_time\": 410.06198239326477\n",
      "}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "dataset_small = dataset.select(range(50))\n",
    "_ = run_model(model=model, dataset=dataset_small)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "202f4a86-b6dc-4144-9489-1f897830e865",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1302245"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "del dataset_small, _\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44f2688b-c597-4504-b771-ecb4a493cdec",
   "metadata": {},
   "source": [
    "# -- TO_DO Вывод"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bd9c167-a16f-4c34-b1c3-8dde9595533a",
   "metadata": {},
   "source": [
    "# PTQ Dynamic\n",
    "Простейшая восьмибитная квантизация в одну строчку."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "fe337252-49dd-44c9-8f6e-a38b68287cde",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size (MB): 6174.372281\n"
     ]
    }
   ],
   "source": [
    "print_size_of_model(pruned_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b548bcbb-4bab-4998-9e40-438568842097",
   "metadata": {},
   "outputs": [],
   "source": [
    "modules_to_quantize = {torch.nn.Linear}\n",
    "qmodel = tq.quantize_dynamic(\n",
    "    pruned_model, \n",
    "    modules_to_quantize, \n",
    "    dtype=torch.qint8\n",
    ")\n",
    "print_size_of_model(qmodel)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a02b80e-9abc-42dd-904b-37bcf1c03af2",
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = profile_sample(116, trace_path=\"whisper_perfetto_large-v3_quanted_pruned.json\", model=qmodel)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30c8bf6d-3a00-410a-9f86-448027abd0cb",
   "metadata": {},
   "source": [
    "# -- TODO Вывод\n",
    "Мы получили значительное ускорение инференса. Попробуем снять замеры качества с учётом torch.compile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "5bc0ce6c-adf0-49b5-bb9a-ff8acc037c0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Perfetto trace saved to whisper_perfetto_large-v3_quanted_compiled.json\n",
      "-----------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "                                                 Name    Self CPU %      Self CPU   CPU total %     CPU total  CPU time avg       CPU Mem  Self CPU Mem    # of Calls  \n",
      "-----------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "                                     whisper.generate         8.22%     634.960ms       100.00%        7.726s        7.726s         112 B      -6.85 GB             1  \n",
      "                            quantized::linear_dynamic        48.54%        3.750s        49.43%        3.819s     929.023us       2.55 GB      -2.55 GB          4111  \n",
      "                   aten::scaled_dot_product_attention         0.10%       7.414ms        16.53%        1.277s       1.288ms     240.00 MB      -3.75 MB           992  \n",
      "    aten::_scaled_dot_product_flash_attention_for_cpu        15.84%        1.223s        16.44%        1.270s       1.280ms     243.75 MB    -155.99 MB           992  \n",
      "                                     aten::contiguous         0.02%       1.767ms        11.46%     885.782ms       1.973ms       1.84 GB           0 B           449  \n",
      "                                          aten::clone         0.11%       8.360ms        11.44%     884.227ms       1.902ms       1.84 GB           0 B           465  \n",
      "                                          aten::copy_        11.32%     874.642ms        11.32%     874.642ms     530.729us           0 B           0 B          1648  \n",
      "                                            aten::cat         5.02%     388.120ms         5.06%     390.632ms     369.567us     527.72 MB     527.72 MB          1057  \n",
      "                                     aten::layer_norm         0.10%       7.417ms         3.06%     236.377ms     155.511us     484.60 MB    -774.69 KB          1520  \n",
      "                              aten::native_layer_norm         0.96%      73.789ms         2.96%     228.960ms     150.632us     485.36 MB    -476.07 MB          1520  \n",
      "-----------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "Self CPU time total: 7.726s\n",
      "\n"
     ]
    }
   ],
   "source": [
    "qmodel = torch.compile(qmodel)\n",
    "_ = profile_sample(116, trace_path=\"whisper_perfetto_large-v3_quanted_pruned_compiled.json\", model=qmodel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "0f043081-02a2-4a83-bc48-7286f73b5771",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|▎                                                                                                                                                                                                            | 1/793 [00:06<1:27:06,  6.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "referenct:\n",
      "можешь включить сериал теория большого взрыва\n",
      "hypothesis:\n",
      " Можешь включить сериал «Теория большого взрыва»?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|█████████████                                                                                                                                                                                               | 51/793 [04:59<1:16:07,  6.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "referenct:\n",
      "покажи на смотрешке канал бридж тв\n",
      "hypothesis:\n",
      " Покажи на сматрёшке канал Бридж ТВ.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|█████████████████████████▊                                                                                                                                                                                 | 101/793 [09:55<1:03:30,  5.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "referenct:\n",
      "асият иванов\n",
      "hypothesis:\n",
      " Асиат Иванов\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 19%|██████████████████████████████████████▋                                                                                                                                                                    | 151/793 [14:45<1:04:01,  5.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "referenct:\n",
      "заказать тольятти молоко три и два процента жирности один литр\n",
      "hypothesis:\n",
      " Заказать в Тольятти молоко 3,2% жирности 1 литр.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|███████████████████████████████████████████████████▉                                                                                                                                                         | 201/793 [19:34<57:09,  5.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "referenct:\n",
      "фильм самый лучший день\n",
      "hypothesis:\n",
      " Фильм «Самый лучший день»\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 32%|████████████████████████████████████████████████████████████████▉                                                                                                                                            | 251/793 [24:21<49:43,  5.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "referenct:\n",
      "лилль\n",
      "hypothesis:\n",
      " Лиль\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 38%|█████████████████████████████████████████████████████████████████████████████▊                                                                                                                               | 301/793 [29:07<46:57,  5.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "referenct:\n",
      "брюс уиллис\n",
      "hypothesis:\n",
      " Брюс Уиллис\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 44%|██████████████████████████████████████████████████████████████████████████████████████████▋                                                                                                                  | 351/793 [34:07<42:57,  5.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "referenct:\n",
      "ооо грузовой легковой шиномонтаж\n",
      "hypothesis:\n",
      " О-о-о, грузовой легковой шиномонтаж.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 51%|███████████████████████████████████████████████████████████████████████████████████████████████████████▋                                                                                                     | 401/793 [39:07<39:35,  6.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "referenct:\n",
      "покажи мне амирана сардарова на ютюбе\n",
      "hypothesis:\n",
      " Покажи мне Амирана Сардарова на YouTube.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 57%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                                                                                        | 451/793 [43:56<35:12,  6.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "referenct:\n",
      "арсенал манчестер сити\n",
      "hypothesis:\n",
      " Арсенал Манчестер Сити\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 63%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                                                                           | 501/793 [48:49<31:09,  6.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "referenct:\n",
      "у тебя в каталоге есть сериал охотники за бриллиантами первый сезон\n",
      "hypothesis:\n",
      " У тебя в каталоге есть сериал «Охотники за бриллиантами. Первый сезон».\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 69%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍                                                              | 551/793 [53:35<22:31,  5.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "referenct:\n",
      "джой сколько страниц в собака баскервилей\n",
      "hypothesis:\n",
      " Джой, сколько страниц в собак обоскервилий?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 76%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎                                                 | 601/793 [58:23<17:20,  5.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "referenct:\n",
      "шант ньюс\n",
      "hypothesis:\n",
      " Шант Ньюс\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 82%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋                                    | 651/793 [1:03:06<13:06,  5.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "referenct:\n",
      "танго любви найди\n",
      "hypothesis:\n",
      " Танго любви найди.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 88%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍                       | 701/793 [1:07:56<08:47,  5.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "referenct:\n",
      "вячеслав владимирович месяцев\n",
      "hypothesis:\n",
      " Вячеслав Владимирович Месяцев\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 95%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏          | 751/793 [1:12:49<03:59,  5.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "referenct:\n",
      "футбольный матч тоттенхэм лестер\n",
      "hypothesis:\n",
      " Футбольный матч Тоттенхэм-Лестер\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 793/793 [1:16:50<00:00,  5.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "large-v3\n",
      "{\n",
      "  \"total_samples\": 793,\n",
      "  \"avg_wer\": 0.4739530218975364,\n",
      "  \"avg_cer\": 0.16637995920858634,\n",
      "  \"avg_time_per_audio\": 5.805704870861385,\n",
      "  \"total_time\": 4603.923962593079\n",
      "}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "summary = run_model(verbose=True, model=qmodel, dataset=dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "66f3155b-d6e9-4d88-ad25-3991791dbbb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"whisper_metric.json\", \"r\", encoding=\"utf-8\") as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "data[\"large-v3_cpu_quanted_pruned\"] = summary\n",
    "\n",
    "with open(\"whisper_metric.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(data, f, ensure_ascii=True, indent=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41ac924e-6383-4087-9c4e-bf065574c4fd",
   "metadata": {},
   "source": [
    "# --TO_DO Выведи только исходную метрику для CPU/GPU, large-v3_cpu_quanted, large-v3_cuda_global_magnitude_pruning_0.81 и large-v3_cpu_quanted_pruned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "275ae158-40db-4c99-9b23-2cece29e4235",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tiny</th>\n",
       "      <th>small</th>\n",
       "      <th>iarge-v3</th>\n",
       "      <th>large-v3_cuda</th>\n",
       "      <th>large-v3_cpu_quanted</th>\n",
       "      <th>large-v3_cuda_quanted</th>\n",
       "      <th>large-v3_cuda_autocast_compile</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>total_samples</th>\n",
       "      <td>793.000000</td>\n",
       "      <td>793.000000</td>\n",
       "      <td>793.000000</td>\n",
       "      <td>793.000000</td>\n",
       "      <td>793.000000</td>\n",
       "      <td>793.000000</td>\n",
       "      <td>793.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>avg_wer</th>\n",
       "      <td>1.049771</td>\n",
       "      <td>0.523011</td>\n",
       "      <td>0.440303</td>\n",
       "      <td>0.440303</td>\n",
       "      <td>0.473953</td>\n",
       "      <td>0.447231</td>\n",
       "      <td>0.442587</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>avg_cer</th>\n",
       "      <td>0.486142</td>\n",
       "      <td>0.207796</td>\n",
       "      <td>0.158293</td>\n",
       "      <td>0.158293</td>\n",
       "      <td>0.166380</td>\n",
       "      <td>0.158552</td>\n",
       "      <td>0.158944</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>avg_time_per_audio</th>\n",
       "      <td>0.168900</td>\n",
       "      <td>0.682818</td>\n",
       "      <td>7.948655</td>\n",
       "      <td>0.838627</td>\n",
       "      <td>5.805705</td>\n",
       "      <td>2.843514</td>\n",
       "      <td>0.997778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>total_time</th>\n",
       "      <td>133.937801</td>\n",
       "      <td>541.474906</td>\n",
       "      <td>6303.283459</td>\n",
       "      <td>665.031494</td>\n",
       "      <td>4603.923963</td>\n",
       "      <td>2254.906898</td>\n",
       "      <td>791.237885</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          tiny       small     iarge-v3  large-v3_cuda  \\\n",
       "total_samples       793.000000  793.000000   793.000000     793.000000   \n",
       "avg_wer               1.049771    0.523011     0.440303       0.440303   \n",
       "avg_cer               0.486142    0.207796     0.158293       0.158293   \n",
       "avg_time_per_audio    0.168900    0.682818     7.948655       0.838627   \n",
       "total_time          133.937801  541.474906  6303.283459     665.031494   \n",
       "\n",
       "                    large-v3_cpu_quanted  large-v3_cuda_quanted  \\\n",
       "total_samples                 793.000000             793.000000   \n",
       "avg_wer                         0.473953               0.447231   \n",
       "avg_cer                         0.166380               0.158552   \n",
       "avg_time_per_audio              5.805705               2.843514   \n",
       "total_time                   4603.923963            2254.906898   \n",
       "\n",
       "                    large-v3_cuda_autocast_compile  \n",
       "total_samples                           793.000000  \n",
       "avg_wer                                   0.442587  \n",
       "avg_cer                                   0.158944  \n",
       "avg_time_per_audio                        0.997778  \n",
       "total_time                              791.237885  "
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "9a325f2a-0389-4d78-b0f3-0e06151267f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Сохраняем state_dict квантованной модели\n",
    "torch.save(qmodel.state_dict(), \"./whisper-large-v3-quantized-dynamic-pruned.pth\")\n",
    "\n",
    "# Также сохраните конфигурацию отдельно (она не меняется)\n",
    "qmodel.config.save_pretrained(\"./whisper-large-v3-quantized-dynamic-pruned\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "a4678e7c-6d0a-43e2-9fc3-915e7a5d2540",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'qmodel' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[52]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[38;5;28;01mdel\u001b[39;00m \u001b[43mqmodel\u001b[49m, _\n\u001b[32m      2\u001b[39m gc.collect()\n",
      "\u001b[31mNameError\u001b[39m: name 'qmodel' is not defined"
     ]
    }
   ],
   "source": [
    "del qmodel, _\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1cef747-1a81-4e59-bbaf-bbf6cc8f3bf9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
