{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b2f0b99c-4578-44b6-a456-61b7f912bf87",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "from torch.profiler import profile, record_function, ProfilerActivity\n",
    "import pandas as pd\n",
    "from datasets import load_dataset\n",
    "from transformers import WhisperProcessor, WhisperForConditionalGeneration\n",
    "import torch.quantization\n",
    "import torch.ao.quantization as tq\n",
    "import gc\n",
    "\n",
    "import jiwer\n",
    "from jiwer import (\n",
    "    Compose,\n",
    "    ToLowerCase,\n",
    "    RemoveMultipleSpaces,\n",
    "    Strip,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9652d098-c5a7-4e57-a3f4-bb0ec2ecc698",
   "metadata": {},
   "source": [
    "# Final experiment\n",
    "В этом ноутбуке проверяется гипотеза, что пропруненная ранее модель с базовой квантизацией и компиляцией даёт лучшие результаты. Прогон ноутбука произведён на тестовом сервере прунинга, поэтому результаты могут незначительно отличаться от метрик бэйзлайна.\n",
    "\n",
    "Все значения профилировщика были сняты в прогоне на чистовую вне изолированной среды, поэтому значения могут отличаться, но статистически сводятся к итоговым метрикам."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ae18e1e5-24fc-409b-babd-cef272baeae7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_size_of_model(model):\n",
    "    \"\"\" Prints the real size of the model \"\"\"\n",
    "    torch.save(model.state_dict(), \"temp.p\")\n",
    "    print('Size (MB):', os.path.getsize(\"temp.p\")/1e6)\n",
    "    os.remove('temp.p')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e58fb1fa-874c-410a-b47d-180b6115d512",
   "metadata": {},
   "outputs": [],
   "source": [
    "def asr_metrics(hypothesis: str, reference: str):\n",
    "    tr = Compose([ToLowerCase(), RemoveMultipleSpaces(), Strip()])\n",
    "\n",
    "    ref_tr = tr(reference)\n",
    "    hyp_tr = tr(hypothesis)\n",
    "\n",
    "    out = jiwer.process_words(ref_tr, hyp_tr)\n",
    "    wer = out.wer\n",
    "    # S, D, I = out.substitutions, out.deletions, out.insertions\n",
    "\n",
    "    cer = jiwer.cer(ref_tr, hyp_tr) # ?????\n",
    "\n",
    "    return {\n",
    "        \"wer\": wer,\n",
    "        \"cer\": cer,\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "059ea448-06fe-4a2b-bc43-1ced9c20b905",
   "metadata": {},
   "outputs": [],
   "source": [
    "def profile_sample(sample_idx=0, trace_path=\"whisper_perfetto_large-v3.json\", sort_by=\"cpu_time_total\", model=None):\n",
    "    example = dataset[sample_idx]\n",
    "    audio_array = example[\"audio\"][\"array\"]\n",
    "    sampling_rate = example[\"audio\"][\"sampling_rate\"]\n",
    "\n",
    "    inputs = processor(audio_array, sampling_rate=sampling_rate, return_tensors=\"pt\").input_features\n",
    "\n",
    "    with profile(\n",
    "        activities=[ProfilerActivity.CPU],\n",
    "        record_shapes=True,\n",
    "        profile_memory=True,\n",
    "        with_stack=False,\n",
    "    ) as prof:\n",
    "        with record_function(\"whisper.generate\"):\n",
    "            predicted_ids = model.generate(inputs, forced_decoder_ids=forced_decoder_ids)\n",
    "\n",
    "    prof.export_chrome_trace(trace_path)\n",
    "    print(f\"Perfetto trace saved to {trace_path}\")\n",
    "    print(prof.key_averages().table(\n",
    "        sort_by=sort_by,\n",
    "        row_limit=10\n",
    "    ))\n",
    "    return processor.decode(predicted_ids[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8ca2588d-c490-4ed8-a4d2-63cdccf5079e",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = load_dataset(\"bond005/sberdevices_golos_10h_crowd\", split=\"validation\", cache_dir=\"datasets\")\n",
    "# dataset = dataset.select(range(100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "afaa4d97-cb9c-4238-bbde-f955c671a066",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size (MB): 6174.372281\n"
     ]
    }
   ],
   "source": [
    "processor = WhisperProcessor.from_pretrained(\"models--openai--whisper-large-v3/snapshots/06f233fe06e710322aca913c1bc4249a0d71fce1\")\n",
    "model = WhisperForConditionalGeneration.from_pretrained(\"models--openai--whisper-large-v3/snapshots/06f233fe06e710322aca913c1bc4249a0d71fce1\")\n",
    "forced_decoder_ids = processor.get_decoder_prompt_ids(language=\"russian\", task=\"transcribe\")\n",
    "print_size_of_model(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "af428acb-7dd7-4215-8591-156f44a1f954",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WhisperForConditionalGeneration(\n",
      "  (model): WhisperModel(\n",
      "    (encoder): WhisperEncoder(\n",
      "      (conv1): Conv1d(128, 1280, kernel_size=(3,), stride=(1,), padding=(1,))\n",
      "      (conv2): Conv1d(1280, 1280, kernel_size=(3,), stride=(2,), padding=(1,))\n",
      "      (embed_positions): Embedding(1500, 1280)\n",
      "      (layers): ModuleList(\n",
      "        (0-31): 32 x WhisperEncoderLayer(\n",
      "          (self_attn): WhisperAttention(\n",
      "            (k_proj): Linear(in_features=1280, out_features=1280, bias=False)\n",
      "            (v_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
      "            (q_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
      "            (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
      "          )\n",
      "          (self_attn_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
      "          (activation_fn): GELUActivation()\n",
      "          (fc1): Linear(in_features=1280, out_features=5120, bias=True)\n",
      "          (fc2): Linear(in_features=5120, out_features=1280, bias=True)\n",
      "          (final_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
      "        )\n",
      "      )\n",
      "      (layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
      "    )\n",
      "    (decoder): WhisperDecoder(\n",
      "      (embed_tokens): Embedding(51866, 1280, padding_idx=50256)\n",
      "      (embed_positions): WhisperPositionalEmbedding(448, 1280)\n",
      "      (layers): ModuleList(\n",
      "        (0-31): 32 x WhisperDecoderLayer(\n",
      "          (self_attn): WhisperAttention(\n",
      "            (k_proj): Linear(in_features=1280, out_features=1280, bias=False)\n",
      "            (v_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
      "            (q_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
      "            (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
      "          )\n",
      "          (activation_fn): GELUActivation()\n",
      "          (self_attn_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
      "          (encoder_attn): WhisperAttention(\n",
      "            (k_proj): Linear(in_features=1280, out_features=1280, bias=False)\n",
      "            (v_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
      "            (q_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
      "            (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
      "          )\n",
      "          (encoder_attn_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
      "          (fc1): Linear(in_features=1280, out_features=5120, bias=True)\n",
      "          (fc2): Linear(in_features=5120, out_features=1280, bias=True)\n",
      "          (final_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
      "        )\n",
      "      )\n",
      "      (layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
      "    )\n",
      "  )\n",
      "  (proj_out): Linear(in_features=1280, out_features=51866, bias=False)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# Посмотрим на архитектуру модели\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9282cdb6-2d8f-41d7-8d7c-311729106c5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_model(verbose=False, model=None, dataset=None):\n",
    "    results = []\n",
    "    i = 0\n",
    "    for audio in tqdm(dataset):\n",
    "        audio_array = audio[\"audio\"][\"array\"]\n",
    "        sampling_rate = audio[\"audio\"][\"sampling_rate\"]\n",
    "        reference = audio[\"transcription\"]\n",
    "    \n",
    "        start_time = time.time()\n",
    "        input_features = processor(audio_array, sampling_rate=sampling_rate, return_tensors=\"pt\").input_features \n",
    "        predicted_ids = model.generate(input_features, forced_decoder_ids=forced_decoder_ids)[0] #Уточнить в зависимости от выбранной модели\n",
    "        hypothesis = processor.decode(predicted_ids)\n",
    "        run_time = time.time() - start_time\n",
    "        metrics = asr_metrics(hypothesis, reference)\n",
    "        metrics[\"run_time_sec\"] = run_time\n",
    "        if verbose:\n",
    "            if i % 50 == 0:\n",
    "                print(\"referenct:\")\n",
    "                print(reference)\n",
    "                print(\"hypothesis:\")\n",
    "                print(hypothesis)\n",
    "            i += 1\n",
    "        results.append(metrics)\n",
    "\n",
    "    df_results = pd.DataFrame(results)\n",
    "    \n",
    "    summary = {\n",
    "        \"total_samples\": len(df_results),\n",
    "        \"avg_wer\": df_results[\"wer\"].mean(),\n",
    "        \"avg_cer\": df_results[\"cer\"].mean(),\n",
    "        \"avg_time_per_audio\": df_results[\"run_time_sec\"].mean(),\n",
    "        \"total_time\": df_results[\"run_time_sec\"].sum(),\n",
    "    }\n",
    "    \n",
    "    print(\"large-v3\")\n",
    "    print(json.dumps(summary, ensure_ascii=True, indent=2))\n",
    "    return summary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ea957dd-af6f-41e5-a42b-01a8f9634045",
   "metadata": {},
   "source": [
    "# CPU\n",
    "Профилировка базовой модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "46cab216-b2b7-47ff-9349-a51e4218f2e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom `forced_decoder_ids` from the (generation) config. This is deprecated in favor of the `task` and `language` flags/config options.\n",
      "The attention mask is not set and cannot be inferred from input because pad token is same as eos token. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Perfetto trace saved to whisper_perfetto_large-v3_base.json\n",
      "-----------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "                                                 Name    Self CPU %      Self CPU   CPU total %     CPU total  CPU time avg       CPU Mem  Self CPU Mem    # of Calls  \n",
      "-----------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "                                     whisper.generate         3.99%     332.154ms       100.00%        8.325s        8.325s         112 B      -6.39 GB             1  \n",
      "                                         aten::linear         0.48%      39.801ms        71.79%        5.976s       1.454ms       2.55 GB           0 B          4111  \n",
      "                                          aten::addmm        57.63%        4.797s        59.86%        4.983s       1.403ms       2.09 GB       2.09 GB          3552  \n",
      "                   aten::scaled_dot_product_attention         0.09%       7.267ms        13.43%        1.118s       1.127ms     240.01 MB      -3.74 MB           992  \n",
      "    aten::_scaled_dot_product_flash_attention_for_cpu        13.05%        1.086s        13.34%        1.111s       1.120ms     243.75 MB    -155.97 MB           992  \n",
      "                                         aten::matmul         0.09%       7.750ms        10.91%     908.265ms       1.625ms     475.12 MB           0 B           559  \n",
      "                                             aten::mm        10.77%     896.437ms        10.77%     896.901ms       1.604ms     475.12 MB     475.12 MB           559  \n",
      "                                          aten::copy_         5.30%     441.588ms         5.30%     441.588ms      84.921us           0 B           0 B          5200  \n",
      "                                     aten::contiguous         0.02%       1.558ms         3.31%     275.791ms     614.235us       1.84 GB           0 B           449  \n",
      "                                          aten::clone         0.06%       5.077ms         3.30%     274.384ms     590.072us       1.84 GB           0 B           465  \n",
      "-----------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "Self CPU time total: 8.325s\n",
      "\n"
     ]
    }
   ],
   "source": [
    "_ = profile_sample(116, trace_path=\"whisper_perfetto_large-v3_base.json\", model=model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2ed15432-37b1-4633-a054-ddb4452f4871",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1288802"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# del model, _\n",
    "# gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "196f4e55-9289-44e5-a09b-29d1e76b3e5d",
   "metadata": {},
   "source": [
    "Профилировка запруненной модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2421e128-1a38-433c-b43a-d9495bb8f96f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_state_dict(torch.load(\"whisper_pruned_iter3.pt\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6a798884-aa11-4fa5-a1bd-2f3d6a13ef3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Perfetto trace saved to whisper_perfetto_large-v3_pruned_base.json\n",
      "-----------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "                                                 Name    Self CPU %      Self CPU   CPU total %     CPU total  CPU time avg       CPU Mem  Self CPU Mem    # of Calls  \n",
      "-----------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "                                     whisper.generate         3.06%     236.690ms       100.00%        7.732s        7.732s         112 B      -6.39 GB             1  \n",
      "                                         aten::linear         0.49%      38.039ms        74.94%        5.794s       1.409ms       2.55 GB           0 B          4111  \n",
      "                                          aten::addmm        62.04%        4.796s        62.90%        4.863s       1.369ms       2.09 GB       2.09 GB          3552  \n",
      "                   aten::scaled_dot_product_attention         0.07%       5.223ms        14.52%        1.123s       1.132ms     240.01 MB      -3.74 MB           992  \n",
      "    aten::_scaled_dot_product_flash_attention_for_cpu        14.16%        1.095s        14.45%        1.118s       1.127ms     243.75 MB    -155.87 MB           992  \n",
      "                                         aten::matmul         0.09%       6.913ms        10.98%     849.106ms       1.519ms     475.12 MB           0 B           559  \n",
      "                                             aten::mm        10.84%     838.401ms        10.85%     838.846ms       1.501ms     475.12 MB     475.12 MB           559  \n",
      "                                          aten::copy_         3.01%     232.911ms         3.01%     232.911ms      44.791us           0 B           0 B          5200  \n",
      "                                     aten::contiguous         0.02%       1.390ms         2.40%     185.319ms     412.736us       1.84 GB           0 B           449  \n",
      "                                          aten::clone         0.06%       4.437ms         2.38%     184.059ms     395.826us       1.84 GB           0 B           465  \n",
      "-----------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "Self CPU time total: 7.732s\n",
      "\n"
     ]
    }
   ],
   "source": [
    "_ = profile_sample(116, trace_path=\"whisper_perfetto_large-v3_pruned_base.json\", model=model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "58cf44a1-10a3-4af3-933e-cebf88d068b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████| 50/50 [06:12<00:00,  7.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "large-v3\n",
      "{\n",
      "  \"total_samples\": 50,\n",
      "  \"avg_wer\": 0.3959776334776335,\n",
      "  \"avg_cer\": 0.1406573182624397,\n",
      "  \"avg_time_per_audio\": 7.44771089553833,\n",
      "  \"total_time\": 372.3855447769165\n",
      "}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "dataset_small = dataset.select(range(50))\n",
    "_ = run_model(model=model, dataset=dataset_small)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "202f4a86-b6dc-4144-9489-1f897830e865",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1288846"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "del dataset_small, _\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44f2688b-c597-4504-b771-ecb4a493cdec",
   "metadata": {},
   "source": [
    "Явно видно полусекундное ускорение. Топ операций не поменялся, впрочем, это было ожидаемо."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bd9c167-a16f-4c34-b1c3-8dde9595533a",
   "metadata": {},
   "source": [
    "# PTQ Dynamic\n",
    "Простейшая восьмибитная квантизация в одну строчку."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fe337252-49dd-44c9-8f6e-a38b68287cde",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size (MB): 6174.372281\n"
     ]
    }
   ],
   "source": [
    "print_size_of_model(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b548bcbb-4bab-4998-9e40-438568842097",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_536/1967412630.py:2: DeprecationWarning: torch.ao.quantization is deprecated and will be removed in 2.10. \n",
      "For migrations of users: \n",
      "1. Eager mode quantization (torch.ao.quantization.quantize, torch.ao.quantization.quantize_dynamic), please migrate to use torchao eager mode quantize_ API instead \n",
      "2. FX graph mode quantization (torch.ao.quantization.quantize_fx.prepare_fx,torch.ao.quantization.quantize_fx.convert_fx, please migrate to use torchao pt2e quantization API instead (prepare_pt2e, convert_pt2e) \n",
      "3. pt2e quantization has been migrated to torchao (https://github.com/pytorch/ao/tree/main/torchao/quantization/pt2e) \n",
      "see https://github.com/pytorch/ao/issues/2259 for more details\n",
      "  qmodel = tq.quantize_dynamic(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size (MB): 1837.108365\n"
     ]
    }
   ],
   "source": [
    "modules_to_quantize = {torch.nn.Linear}\n",
    "qmodel = tq.quantize_dynamic(\n",
    "    model, \n",
    "    modules_to_quantize, \n",
    "    dtype=torch.qint8\n",
    ")\n",
    "print_size_of_model(qmodel)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4a02b80e-9abc-42dd-904b-37bcf1c03af2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Perfetto trace saved to whisper_perfetto_large-v3_quanted_pruned.json\n",
      "-----------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "                                                 Name    Self CPU %      Self CPU   CPU total %     CPU total  CPU time avg       CPU Mem  Self CPU Mem    # of Calls  \n",
      "-----------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "                                     whisper.generate         6.57%     377.013ms       100.00%        5.735s        5.735s         112 B      -6.39 GB             1  \n",
      "                            quantized::linear_dynamic        61.47%        3.526s        62.10%        3.561s     866.279us       2.55 GB      -2.55 GB          4111  \n",
      "                   aten::scaled_dot_product_attention         0.09%       5.023ms        19.38%        1.112s       1.121ms     240.01 MB      -3.74 MB           992  \n",
      "    aten::_scaled_dot_product_flash_attention_for_cpu        18.85%        1.081s        19.29%        1.107s       1.116ms     243.75 MB    -155.95 MB           992  \n",
      "                                     aten::contiguous         0.03%       1.459ms         4.19%     240.258ms     535.095us       1.84 GB           0 B           449  \n",
      "                                          aten::clone         0.08%       4.361ms         4.17%     238.932ms     513.831us       1.84 GB           0 B           465  \n",
      "                                          aten::copy_         4.01%     230.163ms         4.01%     230.163ms     139.662us           0 B           0 B          1648  \n",
      "                                     aten::layer_norm         0.09%       4.953ms         2.96%     169.918ms     111.788us     484.60 MB    -774.00 KB          1520  \n",
      "                              aten::native_layer_norm         0.54%      30.749ms         2.88%     164.965ms     108.530us     485.36 MB    -476.01 MB          1520  \n",
      "                                            aten::add         2.78%     159.549ms         2.78%     159.549ms     102.802us     484.60 MB     484.60 MB          1552  \n",
      "-----------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "Self CPU time total: 5.735s\n",
      "\n"
     ]
    }
   ],
   "source": [
    "_ = profile_sample(116, trace_path=\"whisper_perfetto_large-v3_quanted_pruned.json\", model=qmodel)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30c8bf6d-3a00-410a-9f86-448027abd0cb",
   "metadata": {},
   "source": [
    "Мы получили значительное ускорение инференса. Попробуем снять замеры качества с учётом torch.compile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5bc0ce6c-adf0-49b5-bb9a-ff8acc037c0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Perfetto trace saved to whisper_perfetto_large-v3_quanted_pruned_compiled.json\n",
      "-----------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "                                                 Name    Self CPU %      Self CPU   CPU total %     CPU total  CPU time avg       CPU Mem  Self CPU Mem    # of Calls  \n",
      "-----------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "                                     whisper.generate         6.52%     360.600ms       100.00%        5.534s        5.534s         112 B      -6.39 GB             1  \n",
      "                            quantized::linear_dynamic        61.67%        3.413s        62.35%        3.451s     839.412us       2.55 GB      -2.55 GB          4111  \n",
      "                   aten::scaled_dot_product_attention         0.08%       4.604ms        20.28%        1.122s       1.131ms     240.01 MB      -3.74 MB           992  \n",
      "    aten::_scaled_dot_product_flash_attention_for_cpu        19.79%        1.095s        20.19%        1.118s       1.127ms     243.75 MB    -155.99 MB           992  \n",
      "                                     aten::contiguous         0.02%       1.378ms         3.44%     190.187ms     423.580us       1.84 GB           0 B           449  \n",
      "                                          aten::clone         0.07%       3.980ms         3.41%     188.933ms     406.308us       1.84 GB           0 B           465  \n",
      "                                          aten::copy_         3.14%     173.950ms         3.14%     173.950ms     105.552us           0 B           0 B          1648  \n",
      "                                     aten::layer_norm         0.09%       4.887ms         2.98%     164.681ms     108.343us     484.60 MB    -773.97 KB          1520  \n",
      "                              aten::native_layer_norm         0.52%      28.624ms         2.89%     159.793ms     105.127us     485.36 MB    -475.95 MB          1520  \n",
      "                                            aten::add         2.84%     157.215ms         2.84%     157.215ms     101.298us     484.60 MB     484.60 MB          1552  \n",
      "-----------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "Self CPU time total: 5.534s\n",
      "\n"
     ]
    }
   ],
   "source": [
    "qmodel = torch.compile(qmodel)\n",
    "_ = profile_sample(116, trace_path=\"whisper_perfetto_large-v3_quanted_pruned_compiled.json\", model=qmodel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0f043081-02a2-4a83-bc48-7286f73b5771",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                               | 1/793 [00:05<1:13:54,  5.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "referenct:\n",
      "можешь включить сериал теория большого взрыва\n",
      "hypothesis:\n",
      " Можешь включить сериал «Теория большого взрыва»?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|███▉                                                          | 51/793 [04:22<1:03:30,  5.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "referenct:\n",
      "покажи на смотрешке канал бридж тв\n",
      "hypothesis:\n",
      " Покажи на Смотрёжке канал Бридж ТВ.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|████████                                                       | 101/793 [08:38<57:59,  5.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "referenct:\n",
      "асият иванов\n",
      "hypothesis:\n",
      " Асиат Иванов\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 19%|███████████▉                                                   | 151/793 [13:02<56:36,  5.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "referenct:\n",
      "заказать тольятти молоко три и два процента жирности один литр\n",
      "hypothesis:\n",
      " Заказать в Тольятти молоко 3,2% жирности 1 литр.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|███████████████▉                                               | 201/793 [17:17<49:54,  5.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "referenct:\n",
      "фильм самый лучший день\n",
      "hypothesis:\n",
      " Фильм «Самый лучший день»\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 32%|███████████████████▉                                           | 251/793 [21:29<43:15,  4.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "referenct:\n",
      "лилль\n",
      "hypothesis:\n",
      " Лиль\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 38%|███████████████████████▉                                       | 301/793 [25:42<41:42,  5.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "referenct:\n",
      "брюс уиллис\n",
      "hypothesis:\n",
      " Брюс Уиллис\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 44%|███████████████████████████▉                                   | 351/793 [30:02<37:49,  5.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "referenct:\n",
      "ооо грузовой легковой шиномонтаж\n",
      "hypothesis:\n",
      " О-о-о, грузовой легковой шиномонтаж.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 51%|███████████████████████████████▊                               | 401/793 [34:15<33:31,  5.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "referenct:\n",
      "покажи мне амирана сардарова на ютюбе\n",
      "hypothesis:\n",
      " Покажи мне Амирана Сардарова на YouTube.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 57%|███████████████████████████████████▊                           | 451/793 [38:27<30:14,  5.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "referenct:\n",
      "арсенал манчестер сити\n",
      "hypothesis:\n",
      " Арсенал Манчестер Сити\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 63%|███████████████████████████████████████▊                       | 501/793 [42:43<26:55,  5.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "referenct:\n",
      "у тебя в каталоге есть сериал охотники за бриллиантами первый сезон\n",
      "hypothesis:\n",
      " У тебя в каталоге есть сериал «Охотники за бриллиантами. Первый сезон».\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 69%|███████████████████████████████████████████▊                   | 551/793 [46:55<19:52,  4.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "referenct:\n",
      "джой сколько страниц в собака баскервилей\n",
      "hypothesis:\n",
      " Джой, сколько страниц в собак обоскервений?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 76%|███████████████████████████████████████████████▋               | 601/793 [51:09<15:38,  4.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "referenct:\n",
      "шант ньюс\n",
      "hypothesis:\n",
      " Шант Ньюс\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 82%|███████████████████████████████████████████████████▋           | 651/793 [55:18<11:35,  4.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "referenct:\n",
      "танго любви найди\n",
      "hypothesis:\n",
      " Танго любви найди.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 88%|███████████████████████████████████████████████████████▋       | 701/793 [59:32<07:39,  4.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "referenct:\n",
      "вячеслав владимирович месяцев\n",
      "hypothesis:\n",
      " Вячеслав Владимирович Месяцев\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 95%|█████████████████████████████████████████████████████████▊   | 751/793 [1:03:44<03:31,  5.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "referenct:\n",
      "футбольный матч тоттенхэм лестер\n",
      "hypothesis:\n",
      " Футбольный матч Тоттенхэм-Лестер.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████| 793/793 [1:07:18<00:00,  5.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "large-v3\n",
      "{\n",
      "  \"total_samples\": 793,\n",
      "  \"avg_wer\": 0.4815027581357973,\n",
      "  \"avg_cer\": 0.16642186304337375,\n",
      "  \"avg_time_per_audio\": 5.083663366781959,\n",
      "  \"total_time\": 4031.3450498580933\n",
      "}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "summary = run_model(verbose=True, model=qmodel, dataset=dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "66f3155b-d6e9-4d88-ad25-3991791dbbb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"whisper_metric.json\", \"r\", encoding=\"utf-8\") as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "data[\"large-v3_cpu_quanted_pruned\"] = summary\n",
    "\n",
    "with open(\"whisper_metric.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(data, f, ensure_ascii=True, indent=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0cc96dec",
   "metadata": {},
   "outputs": [],
   "source": [
    "subdata = {\n",
    "    k: data[k]\n",
    "    for k in [\n",
    "        \"large-v3\",\n",
    "        \"large-v3_cuda\",\n",
    "        \"large-v3_cpu_quanted\",\n",
    "        \"large-v3_cpu_global_magnitude_pruning_0.81\",\n",
    "        \"large-v3_cpu_quanted_pruned\",\n",
    "    ]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "275ae158-40db-4c99-9b23-2cece29e4235",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>large-v3</th>\n",
       "      <th>large-v3_cuda</th>\n",
       "      <th>large-v3_cpu_quanted</th>\n",
       "      <th>large-v3_cpu_global_magnitude_pruning_0.81</th>\n",
       "      <th>large-v3_cpu_quanted_pruned</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>total_samples</th>\n",
       "      <td>793.000000</td>\n",
       "      <td>793.000000</td>\n",
       "      <td>793.000000</td>\n",
       "      <td>793.000000</td>\n",
       "      <td>793.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>avg_wer</th>\n",
       "      <td>0.440303</td>\n",
       "      <td>0.440303</td>\n",
       "      <td>0.473953</td>\n",
       "      <td>0.440990</td>\n",
       "      <td>0.481503</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>avg_cer</th>\n",
       "      <td>0.158293</td>\n",
       "      <td>0.158293</td>\n",
       "      <td>0.166380</td>\n",
       "      <td>0.161862</td>\n",
       "      <td>0.166422</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>avg_time_per_audio</th>\n",
       "      <td>7.948655</td>\n",
       "      <td>0.838627</td>\n",
       "      <td>5.805705</td>\n",
       "      <td>7.437316</td>\n",
       "      <td>5.083663</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>total_time</th>\n",
       "      <td>6303.283459</td>\n",
       "      <td>665.031494</td>\n",
       "      <td>4603.923963</td>\n",
       "      <td>5897.791256</td>\n",
       "      <td>4031.345050</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       large-v3  large-v3_cuda  large-v3_cpu_quanted  \\\n",
       "total_samples        793.000000     793.000000            793.000000   \n",
       "avg_wer                0.440303       0.440303              0.473953   \n",
       "avg_cer                0.158293       0.158293              0.166380   \n",
       "avg_time_per_audio     7.948655       0.838627              5.805705   \n",
       "total_time          6303.283459     665.031494           4603.923963   \n",
       "\n",
       "                    large-v3_cpu_global_magnitude_pruning_0.81  \\\n",
       "total_samples                                       793.000000   \n",
       "avg_wer                                               0.440990   \n",
       "avg_cer                                               0.161862   \n",
       "avg_time_per_audio                                    7.437316   \n",
       "total_time                                         5897.791256   \n",
       "\n",
       "                    large-v3_cpu_quanted_pruned  \n",
       "total_samples                        793.000000  \n",
       "avg_wer                                0.481503  \n",
       "avg_cer                                0.166422  \n",
       "avg_time_per_audio                     5.083663  \n",
       "total_time                          4031.345050  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(subdata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9a325f2a-0389-4d78-b0f3-0e06151267f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/c/Users/Odmen/documents/venv/lib/python3.12/site-packages/transformers/configuration_utils.py:407: UserWarning: Some non-default generation parameters are set in the model config. These should go into either a) `model.generation_config` (as opposed to `model.config`); OR b) a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model).This warning will become an exception in the future.\n",
      "Non-default generation parameters: {'max_length': 448, 'begin_suppress_tokens': [220, 50257]}\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Сохраняем state_dict квантованной модели\n",
    "torch.save(qmodel.state_dict(), \"./whisper-large-v3-quantized-dynamic-pruned.pth\")\n",
    "\n",
    "# Также сохраните конфигурацию отдельно (она не меняется)\n",
    "qmodel.config.save_pretrained(\"./whisper-large-v3-quantized-dynamic-pruned\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "a4678e7c-6d0a-43e2-9fc3-915e7a5d2540",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'qmodel' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[52]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[38;5;28;01mdel\u001b[39;00m \u001b[43mqmodel\u001b[49m, _\n\u001b[32m      2\u001b[39m gc.collect()\n",
      "\u001b[31mNameError\u001b[39m: name 'qmodel' is not defined"
     ]
    }
   ],
   "source": [
    "del qmodel, _\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23d4e352-e088-42b1-8396-d941d8e6c8b3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
