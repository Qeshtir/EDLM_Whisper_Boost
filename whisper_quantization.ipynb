{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "158c9b5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/d_alshevskiy/whisper/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "from torch.profiler import profile, record_function, ProfilerActivity\n",
    "import pandas as pd\n",
    "from datasets import load_dataset\n",
    "from transformers import WhisperProcessor, WhisperForConditionalGeneration\n",
    "from torchao.quantization import (\n",
    "    quantize_,\n",
    "    Int8DynamicActivationInt8WeightConfig,\n",
    "    Float8DynamicActivationFloat8WeightConfig,\n",
    "    Float8DynamicActivationInt4WeightConfig,\n",
    "    Int8DynamicActivationInt4WeightConfig,\n",
    ")\n",
    "import jiwer\n",
    "from jiwer import (\n",
    "    Compose,\n",
    "    ToLowerCase,\n",
    "    RemoveMultipleSpaces,\n",
    "    Strip,\n",
    ")\n",
    "from IPython.display import Audio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4afc6765",
   "metadata": {},
   "outputs": [],
   "source": [
    "def asr_metrics(hypothesis: str, reference: str):\n",
    "    tr = Compose([ToLowerCase(), RemoveMultipleSpaces(), Strip()])\n",
    "\n",
    "    ref_tr = tr(reference)\n",
    "    hyp_tr = tr(hypothesis)\n",
    "\n",
    "    out = jiwer.process_words(ref_tr, hyp_tr)\n",
    "    wer = out.wer\n",
    "    # S, D, I = out.substitutions, out.deletions, out.insertions\n",
    "\n",
    "    cer = jiwer.cer(ref_tr, hyp_tr) # ?????\n",
    "\n",
    "    return {\n",
    "        \"wer\": wer,\n",
    "        \"cer\": cer,\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dc37b389",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = load_dataset(\"bond005/sberdevices_golos_10h_crowd\", split=\"validation\") #, split=\"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "58817eec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "WhisperForConditionalGeneration(\n",
       "  (model): WhisperModel(\n",
       "    (encoder): WhisperEncoder(\n",
       "      (conv1): Conv1d(128, 1280, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "      (conv2): Conv1d(1280, 1280, kernel_size=(3,), stride=(2,), padding=(1,))\n",
       "      (embed_positions): Embedding(1500, 1280)\n",
       "      (layers): ModuleList(\n",
       "        (0-31): 32 x WhisperEncoderLayer(\n",
       "          (self_attn): WhisperAttention(\n",
       "            (k_proj): Linear(in_features=1280, out_features=1280, bias=False)\n",
       "            (v_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "            (q_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "            (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "          )\n",
       "          (self_attn_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "          (activation_fn): GELUActivation()\n",
       "          (fc1): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "          (fc2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "          (final_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "      (layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "    (decoder): WhisperDecoder(\n",
       "      (embed_tokens): Embedding(51866, 1280, padding_idx=50256)\n",
       "      (embed_positions): WhisperPositionalEmbedding(448, 1280)\n",
       "      (layers): ModuleList(\n",
       "        (0-31): 32 x WhisperDecoderLayer(\n",
       "          (self_attn): WhisperAttention(\n",
       "            (k_proj): Linear(in_features=1280, out_features=1280, bias=False)\n",
       "            (v_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "            (q_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "            (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "          )\n",
       "          (activation_fn): GELUActivation()\n",
       "          (self_attn_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "          (encoder_attn): WhisperAttention(\n",
       "            (k_proj): Linear(in_features=1280, out_features=1280, bias=False)\n",
       "            (v_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "            (q_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "            (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "          )\n",
       "          (encoder_attn_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "          (fc1): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "          (fc2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "          (final_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "      (layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "  )\n",
       "  (proj_out): Linear(in_features=1280, out_features=51866, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processor = WhisperProcessor.from_pretrained(\"openai/whisper-large-v3\")\n",
    "model = WhisperForConditionalGeneration.from_pretrained(\"openai/whisper-large-v3\")\n",
    "forced_decoder_ids = processor.get_decoder_prompt_ids(language=\"russian\", task=\"transcribe\")\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "81abff84",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/d_alshevskiy/whisper/lib/python3.11/site-packages/torch/__init__.py:1617: UserWarning: Please use the new API settings to control TF32 behavior, such as torch.backends.cudnn.conv.fp32_precision = 'tf32' or torch.backends.cuda.matmul.fp32_precision = 'ieee'. Old settings, e.g, torch.backends.cuda.matmul.allow_tf32 = True, torch.backends.cudnn.allow_tf32 = True, allowTF32CuDNN() and allowTF32CuBLAS() will be deprecated after Pytorch 2.9. Please see https://pytorch.org/docs/main/notes/cuda.html#tensorfloat-32-tf32-on-ampere-and-later-devices (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:80.)\n",
      "  _C._set_float32_matmul_precision(precision)\n"
     ]
    }
   ],
   "source": [
    "quantize_(model, Int8DynamicActivationInt4WeightConfig())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "681913ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "WhisperForConditionalGeneration(\n",
       "  (model): WhisperModel(\n",
       "    (encoder): WhisperEncoder(\n",
       "      (conv1): Conv1d(128, 1280, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "      (conv2): Conv1d(1280, 1280, kernel_size=(3,), stride=(2,), padding=(1,))\n",
       "      (embed_positions): Embedding(1500, 1280)\n",
       "      (layers): ModuleList(\n",
       "        (0-31): 32 x WhisperEncoderLayer(\n",
       "          (self_attn): WhisperAttention(\n",
       "            (k_proj): Linear(in_features=1280, out_features=1280, weight=LinearActivationQuantizedTensor(activation=<function _int8_asymm_per_token_quant at 0x7a99aa642b60>, weight=AffineQuantizedTensor(shape=torch.Size([1280, 1280]), block_size=(1, 32), device=cpu, _layout=PlainLayout(), tensor_impl_dtype=torch.int8, quant_min=-8, quant_max=7)))\n",
       "            (v_proj): Linear(in_features=1280, out_features=1280, weight=LinearActivationQuantizedTensor(activation=<function _int8_asymm_per_token_quant at 0x7a99aa642b60>, weight=AffineQuantizedTensor(shape=torch.Size([1280, 1280]), block_size=(1, 32), device=cpu, _layout=PlainLayout(), tensor_impl_dtype=torch.int8, quant_min=-8, quant_max=7)))\n",
       "            (q_proj): Linear(in_features=1280, out_features=1280, weight=LinearActivationQuantizedTensor(activation=<function _int8_asymm_per_token_quant at 0x7a99aa642b60>, weight=AffineQuantizedTensor(shape=torch.Size([1280, 1280]), block_size=(1, 32), device=cpu, _layout=PlainLayout(), tensor_impl_dtype=torch.int8, quant_min=-8, quant_max=7)))\n",
       "            (out_proj): Linear(in_features=1280, out_features=1280, weight=LinearActivationQuantizedTensor(activation=<function _int8_asymm_per_token_quant at 0x7a99aa642b60>, weight=AffineQuantizedTensor(shape=torch.Size([1280, 1280]), block_size=(1, 32), device=cpu, _layout=PlainLayout(), tensor_impl_dtype=torch.int8, quant_min=-8, quant_max=7)))\n",
       "          )\n",
       "          (self_attn_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "          (activation_fn): GELUActivation()\n",
       "          (fc1): Linear(in_features=1280, out_features=5120, weight=LinearActivationQuantizedTensor(activation=<function _int8_asymm_per_token_quant at 0x7a99aa642b60>, weight=AffineQuantizedTensor(shape=torch.Size([5120, 1280]), block_size=(1, 32), device=cpu, _layout=PlainLayout(), tensor_impl_dtype=torch.int8, quant_min=-8, quant_max=7)))\n",
       "          (fc2): Linear(in_features=5120, out_features=1280, weight=LinearActivationQuantizedTensor(activation=<function _int8_asymm_per_token_quant at 0x7a99aa642b60>, weight=AffineQuantizedTensor(shape=torch.Size([1280, 5120]), block_size=(1, 32), device=cpu, _layout=PlainLayout(), tensor_impl_dtype=torch.int8, quant_min=-8, quant_max=7)))\n",
       "          (final_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "      (layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "    (decoder): WhisperDecoder(\n",
       "      (embed_tokens): Embedding(51866, 1280, padding_idx=50256)\n",
       "      (embed_positions): WhisperPositionalEmbedding(448, 1280)\n",
       "      (layers): ModuleList(\n",
       "        (0-31): 32 x WhisperDecoderLayer(\n",
       "          (self_attn): WhisperAttention(\n",
       "            (k_proj): Linear(in_features=1280, out_features=1280, weight=LinearActivationQuantizedTensor(activation=<function _int8_asymm_per_token_quant at 0x7a99aa642b60>, weight=AffineQuantizedTensor(shape=torch.Size([1280, 1280]), block_size=(1, 32), device=cpu, _layout=PlainLayout(), tensor_impl_dtype=torch.int8, quant_min=-8, quant_max=7)))\n",
       "            (v_proj): Linear(in_features=1280, out_features=1280, weight=LinearActivationQuantizedTensor(activation=<function _int8_asymm_per_token_quant at 0x7a99aa642b60>, weight=AffineQuantizedTensor(shape=torch.Size([1280, 1280]), block_size=(1, 32), device=cpu, _layout=PlainLayout(), tensor_impl_dtype=torch.int8, quant_min=-8, quant_max=7)))\n",
       "            (q_proj): Linear(in_features=1280, out_features=1280, weight=LinearActivationQuantizedTensor(activation=<function _int8_asymm_per_token_quant at 0x7a99aa642b60>, weight=AffineQuantizedTensor(shape=torch.Size([1280, 1280]), block_size=(1, 32), device=cpu, _layout=PlainLayout(), tensor_impl_dtype=torch.int8, quant_min=-8, quant_max=7)))\n",
       "            (out_proj): Linear(in_features=1280, out_features=1280, weight=LinearActivationQuantizedTensor(activation=<function _int8_asymm_per_token_quant at 0x7a99aa642b60>, weight=AffineQuantizedTensor(shape=torch.Size([1280, 1280]), block_size=(1, 32), device=cpu, _layout=PlainLayout(), tensor_impl_dtype=torch.int8, quant_min=-8, quant_max=7)))\n",
       "          )\n",
       "          (activation_fn): GELUActivation()\n",
       "          (self_attn_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "          (encoder_attn): WhisperAttention(\n",
       "            (k_proj): Linear(in_features=1280, out_features=1280, weight=LinearActivationQuantizedTensor(activation=<function _int8_asymm_per_token_quant at 0x7a99aa642b60>, weight=AffineQuantizedTensor(shape=torch.Size([1280, 1280]), block_size=(1, 32), device=cpu, _layout=PlainLayout(), tensor_impl_dtype=torch.int8, quant_min=-8, quant_max=7)))\n",
       "            (v_proj): Linear(in_features=1280, out_features=1280, weight=LinearActivationQuantizedTensor(activation=<function _int8_asymm_per_token_quant at 0x7a99aa642b60>, weight=AffineQuantizedTensor(shape=torch.Size([1280, 1280]), block_size=(1, 32), device=cpu, _layout=PlainLayout(), tensor_impl_dtype=torch.int8, quant_min=-8, quant_max=7)))\n",
       "            (q_proj): Linear(in_features=1280, out_features=1280, weight=LinearActivationQuantizedTensor(activation=<function _int8_asymm_per_token_quant at 0x7a99aa642b60>, weight=AffineQuantizedTensor(shape=torch.Size([1280, 1280]), block_size=(1, 32), device=cpu, _layout=PlainLayout(), tensor_impl_dtype=torch.int8, quant_min=-8, quant_max=7)))\n",
       "            (out_proj): Linear(in_features=1280, out_features=1280, weight=LinearActivationQuantizedTensor(activation=<function _int8_asymm_per_token_quant at 0x7a99aa642b60>, weight=AffineQuantizedTensor(shape=torch.Size([1280, 1280]), block_size=(1, 32), device=cpu, _layout=PlainLayout(), tensor_impl_dtype=torch.int8, quant_min=-8, quant_max=7)))\n",
       "          )\n",
       "          (encoder_attn_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "          (fc1): Linear(in_features=1280, out_features=5120, weight=LinearActivationQuantizedTensor(activation=<function _int8_asymm_per_token_quant at 0x7a99aa642b60>, weight=AffineQuantizedTensor(shape=torch.Size([5120, 1280]), block_size=(1, 32), device=cpu, _layout=PlainLayout(), tensor_impl_dtype=torch.int8, quant_min=-8, quant_max=7)))\n",
       "          (fc2): Linear(in_features=5120, out_features=1280, weight=LinearActivationQuantizedTensor(activation=<function _int8_asymm_per_token_quant at 0x7a99aa642b60>, weight=AffineQuantizedTensor(shape=torch.Size([1280, 5120]), block_size=(1, 32), device=cpu, _layout=PlainLayout(), tensor_impl_dtype=torch.int8, quant_min=-8, quant_max=7)))\n",
       "          (final_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "      (layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "  )\n",
       "  (proj_out): Linear(in_features=1280, out_features=51866, weight=LinearActivationQuantizedTensor(activation=<function _int8_asymm_per_token_quant at 0x7a99aa642b60>, weight=AffineQuantizedTensor(shape=torch.Size([51866, 1280]), block_size=(1, 32), device=cpu, _layout=PlainLayout(), tensor_impl_dtype=torch.int8, quant_min=-8, quant_max=7)))\n",
       ")"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "98f23036",
   "metadata": {},
   "outputs": [],
   "source": [
    "gc = model.generation_config\n",
    "gc.language = \"ru\"\n",
    "gc.task = \"transcribe\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e7888efd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/793 [00:00<?, ?it/s]The attention mask is not set and cannot be inferred from input because pad token is same as eos token. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "  0%|          | 1/793 [00:20<4:36:55, 20.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "referenct:\n",
      "можешь включить сериал теория большого взрыва\n",
      "hypothesis:\n",
      " Можешь включить сериал «Теория большого взрыва»?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|▋         | 51/793 [08:47<2:12:40, 10.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "referenct:\n",
      "покажи на смотрешке канал бридж тв\n",
      "hypothesis:\n",
      " Покажи на Смотрёжке канал Бридж ТВ.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|█▎        | 101/793 [17:13<1:42:23,  8.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "referenct:\n",
      "асият иванов\n",
      "hypothesis:\n",
      " Асиат Иванов\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 19%|█▉        | 151/793 [26:01<2:06:32, 11.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "referenct:\n",
      "заказать тольятти молоко три и два процента жирности один литр\n",
      "hypothesis:\n",
      " Заказать тольятти молоко 3,2% жирности 1 литр.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▌       | 201/793 [34:49<1:44:29, 10.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "referenct:\n",
      "фильм самый лучший день\n",
      "hypothesis:\n",
      " Фильм «Самый лучший день»\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 32%|███▏      | 251/793 [43:26<1:20:42,  8.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "referenct:\n",
      "лилль\n",
      "hypothesis:\n",
      " ЛИЛЬ\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 38%|███▊      | 301/793 [52:03<1:26:43, 10.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "referenct:\n",
      "брюс уиллис\n",
      "hypothesis:\n",
      " Брюс Уиллис\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 44%|████▍     | 351/793 [1:01:54<1:19:56, 10.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "referenct:\n",
      "ооо грузовой легковой шиномонтаж\n",
      "hypothesis:\n",
      " О-о-о, грузовой легковой шиномонтаж.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 51%|█████     | 401/793 [1:10:54<1:18:20, 11.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "referenct:\n",
      "покажи мне амирана сардарова на ютюбе\n",
      "hypothesis:\n",
      " Покажи мне Амирана Сардарова на ютюбе.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 57%|█████▋    | 451/793 [1:19:42<1:11:59, 12.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "referenct:\n",
      "арсенал манчестер сити\n",
      "hypothesis:\n",
      " Арсенал Манчестер Сити\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 63%|██████▎   | 501/793 [1:28:56<1:09:18, 14.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "referenct:\n",
      "у тебя в каталоге есть сериал охотники за бриллиантами первый сезон\n",
      "hypothesis:\n",
      " У тебя в каталоге есть сериал «Охотники за бриллиантами. Первый сезон».\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 69%|██████▉   | 551/793 [1:37:38<38:54,  9.65s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "referenct:\n",
      "джой сколько страниц в собака баскервилей\n",
      "hypothesis:\n",
      " Джой, сколько страниц в собакобаскервилей?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 76%|███████▌  | 601/793 [1:46:37<27:27,  8.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "referenct:\n",
      "шант ньюс\n",
      "hypothesis:\n",
      " Шант Ньюс\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 82%|████████▏ | 651/793 [1:54:55<21:32,  9.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "referenct:\n",
      "танго любви найди\n",
      "hypothesis:\n",
      " Танго любви найди\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 88%|████████▊ | 701/793 [2:03:44<15:11,  9.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "referenct:\n",
      "вячеслав владимирович месяцев\n",
      "hypothesis:\n",
      " Вячеслав Владимирович Месяцев\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 95%|█████████▍| 751/793 [2:12:23<07:10, 10.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "referenct:\n",
      "футбольный матч тоттенхэм лестер\n",
      "hypothesis:\n",
      " Футбольный матч Тоттенхэм Лестер\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 793/793 [2:19:52<00:00, 10.58s/it]\n"
     ]
    }
   ],
   "source": [
    "results = []\n",
    "i = 0\n",
    "for audio in tqdm(dataset):\n",
    "    audio_array = audio[\"audio\"][\"array\"]\n",
    "    sampling_rate = audio[\"audio\"][\"sampling_rate\"]\n",
    "    reference = audio[\"transcription\"]\n",
    "\n",
    "    start_time = time.time()\n",
    "    input_features = processor(audio_array, sampling_rate=sampling_rate, return_tensors=\"pt\").input_features \n",
    "    predicted_ids = model.generate(input_features, generation_config=gc)[0] #Уточнить в зависимости от выбранной модели\n",
    "    hypothesis = processor.decode(predicted_ids)\n",
    "    run_time = time.time() - start_time\n",
    "    metrics = asr_metrics(hypothesis, reference)\n",
    "    metrics[\"run_time_sec\"] = run_time\n",
    "    if i % 50 == 0:\n",
    "        print(\"referenct:\")\n",
    "        print(reference)\n",
    "        print(\"hypothesis:\")\n",
    "        print(hypothesis)\n",
    "    i += 1\n",
    "    results.append(metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60851653",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/793 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 1/793 [00:06<1:28:48,  6.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "referenct:\n",
      "можешь включить сериал теория большого взрыва\n",
      "hypothesis:\n",
      " Можешь включить сериал «Теория большого взрыва»?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|▋         | 51/793 [04:06<59:20,  4.80s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "referenct:\n",
      "покажи на смотрешке канал бридж тв\n",
      "hypothesis:\n",
      " Покажи на Смотрёжке канал Бридж ТВ.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|█▎        | 101/793 [08:00<50:02,  4.34s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "referenct:\n",
      "асият иванов\n",
      "hypothesis:\n",
      " Асиат Иванов\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 19%|█▉        | 151/793 [11:56<56:40,  5.30s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "referenct:\n",
      "заказать тольятти молоко три и два процента жирности один литр\n",
      "hypothesis:\n",
      " Заказать в Тольятти молоко 3,2% жирности 1 литр.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▌       | 201/793 [15:56<46:50,  4.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "referenct:\n",
      "фильм самый лучший день\n",
      "hypothesis:\n",
      " Фильм «Самый лучший день»\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 32%|███▏      | 251/793 [19:53<35:42,  3.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "referenct:\n",
      "лилль\n",
      "hypothesis:\n",
      " Лиль\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 38%|███▊      | 301/793 [23:53<39:32,  4.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "referenct:\n",
      "брюс уиллис\n",
      "hypothesis:\n",
      " Брюс Уиллис\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 44%|████▍     | 351/793 [28:09<35:49,  4.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "referenct:\n",
      "ооо грузовой легковой шиномонтаж\n",
      "hypothesis:\n",
      " О-о-о, грузовой легковой шиномонтаж.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 51%|█████     | 401/793 [32:19<34:50,  5.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "referenct:\n",
      "покажи мне амирана сардарова на ютюбе\n",
      "hypothesis:\n",
      " Покажи мне Амирана Сардарова на YouTube.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 57%|█████▋    | 451/793 [36:28<30:07,  5.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "referenct:\n",
      "арсенал манчестер сити\n",
      "hypothesis:\n",
      " Арсенал Манчестер Сити\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 63%|██████▎   | 501/793 [40:38<29:43,  6.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "referenct:\n",
      "у тебя в каталоге есть сериал охотники за бриллиантами первый сезон\n",
      "hypothesis:\n",
      " У тебя в каталоге есть сериал «Охотники за бриллиантами. Первый сезон»?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 69%|██████▉   | 551/793 [44:39<17:34,  4.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "referenct:\n",
      "джой сколько страниц в собака баскервилей\n",
      "hypothesis:\n",
      " Джой, сколько страниц в собакобаскервилей?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 76%|███████▌  | 601/793 [48:45<13:59,  4.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "referenct:\n",
      "шант ньюс\n",
      "hypothesis:\n",
      " Шант Ньюс\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 82%|████████▏ | 651/793 [52:45<11:40,  4.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "referenct:\n",
      "танго любви найди\n",
      "hypothesis:\n",
      " Танго любви найди!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 88%|████████▊ | 701/793 [56:46<06:35,  4.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "referenct:\n",
      "вячеслав владимирович месяцев\n",
      "hypothesis:\n",
      " Вячеслав Владимирович Месяцев\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 95%|█████████▍| 751/793 [1:00:43<03:11,  4.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "referenct:\n",
      "футбольный матч тоттенхэм лестер\n",
      "hypothesis:\n",
      " Футбольный матч Тоттенхэм Лестер\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 793/793 [1:04:13<00:00,  4.86s/it]\n"
     ]
    }
   ],
   "source": [
    "# results = []\n",
    "# i = 0\n",
    "# for audio in tqdm(dataset):\n",
    "#     audio_array = audio[\"audio\"][\"array\"]\n",
    "#     sampling_rate = audio[\"audio\"][\"sampling_rate\"]\n",
    "#     reference = audio[\"transcription\"]\n",
    "\n",
    "#     start_time = time.time()\n",
    "#     input_features = processor(audio_array, sampling_rate=sampling_rate, return_tensors=\"pt\").input_features \n",
    "#     predicted_ids = model.generate(input_features, generation_config=gc)[0] #Уточнить в зависимости от выбранной модели\n",
    "#     hypothesis = processor.decode(predicted_ids)\n",
    "#     run_time = time.time() - start_time\n",
    "#     metrics = asr_metrics(hypothesis, reference)\n",
    "#     metrics[\"run_time_sec\"] = run_time\n",
    "#     # if i % 50 == 0:\n",
    "#     #     print(\"referenct:\")\n",
    "#     #     print(reference)\n",
    "#     #     print(\"hypothesis:\")\n",
    "#     #     print(hypothesis)\n",
    "#     # i += 1\n",
    "#     results.append(metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ea2bc440",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "large-v3\n",
      "{\n",
      "  \"total_samples\": 793,\n",
      "  \"avg_wer\": 0.44977964518317604,\n",
      "  \"avg_cer\": 0.16099429957508785,\n",
      "  \"avg_time_per_audio\": 10.5657887552004,\n",
      "  \"total_time\": 8378.670482873917\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "df_results = pd.DataFrame(results)\n",
    "\n",
    "summary = {\n",
    "    \"total_samples\": len(df_results),\n",
    "    \"avg_wer\": df_results[\"wer\"].mean(),\n",
    "    \"avg_cer\": df_results[\"cer\"].mean(),\n",
    "    \"avg_time_per_audio\": df_results[\"run_time_sec\"].mean(),\n",
    "    \"total_time\": df_results[\"run_time_sec\"].sum(),\n",
    "}\n",
    "\n",
    "print(\"large-v3\")\n",
    "print(json.dumps(summary, ensure_ascii=True, indent=2))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
